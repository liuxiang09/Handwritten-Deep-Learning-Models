import torch
from tqdm import tqdm
from .utils import create_nested_tensor, rescale_bboxes
from torchmetrics.detection.mean_ap import MeanAveragePrecision
import torch.nn.functional as F


@torch.no_grad()
def evaluate(model, criterion, data_loader, device):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    criterion.eval()
    
    running_loss = 0.0
    num_batches = len(data_loader)
    
    pbar = tqdm(data_loader, desc="Evaluating")
    for batch_idx, data_dict in enumerate(pbar):
        # ç§»åŠ¨åˆ°è®¾å¤‡
        images = data_dict['images'].to(device)
        targets = [{k: v.to(device) for k, v in t.items()} for t in data_dict['targets']]
        masks = data_dict['masks'].to(device)

        # åˆ›å»ºNestedTensor
        nested_images = create_nested_tensor(images, masks)
        
        # å‰å‘ä¼ æ’­
        outputs = model(nested_images)
        
        # è®¡ç®—æŸå¤±
        loss_dict = criterion(outputs, targets)
        losses = sum(loss_dict[k] * criterion.weight_dict[k] for k in loss_dict.keys())
        
        # ç»Ÿè®¡
        running_loss += losses.item()
        
        # æ›´æ–°è¿›åº¦æ¡
        if batch_idx % 10 == 0:
            pbar.set_postfix({
                'Loss': f"{losses.item():.4f}",
                'CE': f"{loss_dict['loss_ce'].item():.4f}",
                'Bbox': f"{loss_dict['loss_bbox'].item():.4f}",
                'GIoU': f"{loss_dict['loss_giou'].item():.4f}",
            })
    avg_loss = running_loss / num_batches
    print(f"å¹³å‡è¯„ä¼°æŸå¤±: {avg_loss:.4f}")
    return avg_loss


@torch.no_grad()
def evaluate_ap_ar(model, data_loader, device, conf_threshold=0.5): # ã€ä¿®æ”¹ç‚¹ã€‘ç§»é™¤äº† postprocessor å‚æ•°
    """
    è¯„ä¼°æ¨¡å‹çš„mAPå’ŒmARï¼Œæ— éœ€å¤–éƒ¨åå¤„ç†ç±»ã€‚
    
    Args:
        model (torch.nn.Module): æ‚¨è‡ªå·±å®ç°çš„DETRæ¨¡å‹ã€‚
        data_loader (torch.utils.data.DataLoader): è¯„ä¼°ç”¨çš„æ•°æ®åŠ è½½å™¨ã€‚
        device (torch.device): 'cuda' or 'cpu'ã€‚
        conf_threshold (float): ç”¨äºè¿‡æ»¤é¢„æµ‹ç»“æœçš„ç½®ä¿¡åº¦é˜ˆå€¼ã€‚
    """
    model.eval()

    metric = MeanAveragePrecision(box_format='xyxy', iou_type='bbox')

    print("ğŸš€ å¼€å§‹è¿›è¡ŒAP/ARè¯„ä¼°...")
    for data_dict in tqdm(data_loader, desc="Calculating AP/AR"):
        images = data_dict['images'].to(device)
        targets = [{k: v.to(device) for k, v in t.items()} for t in data_dict['targets']]
        masks = data_dict['masks'].to(device)
        nested_images = create_nested_tensor(images, masks)

        # è·å–æ¨¡å‹é¢„æµ‹ç»“æœ
        outputs = model(nested_images)
        
        # åå¤„ç†æ­¥éª¤
        # outputs['pred_logits'] çš„å½¢çŠ¶: [batch_size, num_queries, num_classes + 1]
        # outputs['pred_boxes'] çš„å½¢çŠ¶: [batch_size, num_queries, 4]
        
        # ä½¿ç”¨softmaxå°†logitsè½¬æ¢ä¸ºæ¦‚ç‡
        probs = F.softmax(outputs['pred_logits'], -1)
        
        # è·å–æ¯ä¸ªé¢„æµ‹æ¡†çš„åˆ†æ•°å’Œç±»åˆ«æ ‡ç­¾
        # æˆ‘ä»¬å¿½ç•¥æœ€åä¸€ä¸ªç±»åˆ«ï¼Œå› ä¸ºå®ƒæ˜¯"no object"èƒŒæ™¯ç±»
        scores, labels = probs[..., :-1].max(-1)
        
        # å°†é¢„æµ‹æ¡†ä»å½’ä¸€åŒ–çš„ [center_x, center_y, width, height] æ ¼å¼
        # è½¬æ¢ä¸ºç»å¯¹åƒç´ å€¼çš„ [xmin, ymin, xmax, ymax] æ ¼å¼
        image_sizes = torch.tensor([images.shape[-2], images.shape[-1]], device=images.device).repeat(images.shape[0], 1)  # [B, 2]
        scaled_boxes = rescale_bboxes(outputs['pred_boxes'], image_sizes)

        # æ ¼å¼åŒ– `preds` å’Œ `targets` ä»¥ç¬¦åˆ torchmetrics çš„è¦æ±‚
        preds = []
        for i in range(len(targets)): # éå†batchä¸­çš„æ¯å¼ å›¾ç‰‡
            img_scores = scores[i]
            img_labels = labels[i]
            img_boxes = scaled_boxes[i]

            # æ ¹æ®ç½®ä¿¡åº¦é˜ˆå€¼è¿›è¡Œè¿‡æ»¤
            keep = img_scores > conf_threshold
            
            preds.append({
                'scores': img_scores[keep],
                'labels': img_labels[keep],
                'boxes': img_boxes[keep],
            })

        # `targets` çš„å¤„ç†æ–¹å¼ä¿æŒä¸å˜ï¼ŒåŒæ ·éœ€è¦è½¬æ¢åæ ‡æ ¼å¼
        targets_for_metric = []
        for t in targets:
            # åŒæ ·ä½¿ç”¨rescale_bboxesæ¥è½¬æ¢çœŸå®æ¡†
            # å‡è®¾çœŸå®æ¡†ä¹Ÿæ˜¯cxcywhå½’ä¸€åŒ–æ ¼å¼
            targets_for_metric.append({
                'boxes': rescale_bboxes(t['boxes'], t['orig_size'].unsqueeze(0)).squeeze(0),
                'labels': t['labels'],
            })

        # 5. ä½¿ç”¨å½“å‰æ‰¹æ¬¡çš„æ•°æ®æ›´æ–°è¯„ä¼°å™¨çŠ¶æ€
        metric.update(preds, targets_for_metric)

    # 6. åœ¨æ‰€æœ‰æ•°æ®éƒ½å¤„ç†å®Œæ¯•åï¼Œè®¡ç®—æœ€ç»ˆçš„è¯„ä¼°ç»“æœ
    print("âœ… è¯„ä¼°å®Œæˆï¼Œæ­£åœ¨è®¡ç®—æœ€ç»ˆæŒ‡æ ‡...")
    final_metrics = metric.compute()
    return final_metrics

