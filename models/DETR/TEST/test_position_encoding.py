import torch
from models.DETR.model.position_encoding import PositionEmbeddingSine, PositionEmbeddingLearned
from models.DETR.utils.utils import NestedTensor

# å…¨å±€å‚æ•°é…ç½®
# ä½ç½®ç¼–ç å‚æ•°
D_MODEL = 256
NORMALIZE = True

# æµ‹è¯•æ•°æ®å‚æ•°
BATCH_SIZE = 32
HEIGHT = 30
WIDTH = 40
NUM_CHANNELS = 3
MASK_HEIGHT = 10
MASK_WIDTH = 20


def test_position_encoding():
    """
    å•æµç¨‹ã€ç²¾ç®€ç‰ˆçš„ä½ç½®ç¼–ç æµ‹è¯•
    """
    print("\nğŸš€ å¼€å§‹ç²¾ç®€ç‰ˆä½ç½®ç¼–ç æµ‹è¯•...")
    
    # 1. å‡†å¤‡è¾“å…¥æ•°æ® - ä½¿ç”¨NestedTensor
    tensors = torch.rand(BATCH_SIZE, NUM_CHANNELS, HEIGHT, WIDTH)
    masks = torch.zeros(BATCH_SIZE, HEIGHT, WIDTH, dtype=torch.bool)
    masks[:, :MASK_HEIGHT, :MASK_WIDTH] = True
    nested_tensor = NestedTensor(tensors=tensors, mask=masks)
    print(f"è¾“å…¥NestedTensorå·²åˆ›å»º: tensors shape={nested_tensor.tensors.shape}, mask shape={nested_tensor.mask.shape}")

    # --- æµ‹è¯•æ­£å¼¦ä½ç½®ç¼–ç  (PositionEmbeddingSine) ---
    print("\n--- 1. æµ‹è¯•æ­£å¼¦ä½ç½®ç¼–ç  ---")
    # æ³¨æ„: DETRä¸­xå’Œyç¼–ç ç»´åº¦å„ä¸º num_pos_feats/2ï¼Œç„¶åæ‹¼æ¥
    pos_enc_sine = PositionEmbeddingSine(num_pos_feats=D_MODEL // 2, normalize=NORMALIZE)
    pos_sine = pos_enc_sine(nested_tensor)
    
    # éªŒè¯
    expected_shape = (BATCH_SIZE, D_MODEL, HEIGHT, WIDTH)
    assert pos_sine.shape == expected_shape, f"[Sine] å½¢çŠ¶æ–­è¨€å¤±è´¥! Got {pos_sine.shape}, Expected {expected_shape}"
    assert pos_sine.dtype == torch.float32, f"[Sine] æ•°æ®ç±»å‹åº”ä¸º float32, Got {pos_sine.dtype}"
    assert not torch.isnan(pos_sine).any() and not torch.isinf(pos_sine).any(), "[Sine] è¾“å‡ºåŒ…å« NaN æˆ– Inf!"
    
    print(f"âœ… [Sine] å®ä¾‹åˆ›å»ºæˆåŠŸ")
    print(f"âœ… [Sine] è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {pos_sine.shape}")
    print(f"âœ… [Sine] æ•°æ®ç±»å‹æ­£ç¡®: {pos_sine.dtype}")
    print(f"âœ… [Sine] æ•°å€¼æœ‰æ•ˆ (æ— NaN/Inf)")

    # --- æµ‹è¯•å¯å­¦ä¹ ä½ç½®ç¼–ç  (PositionEmbeddingLearned) ---
    print("\n--- 2. æµ‹è¯•å¯å­¦ä¹ ä½ç½®ç¼–ç  ---")
    pos_enc_learned = PositionEmbeddingLearned(num_pos_feats=D_MODEL // 2)
    # æ³¨æ„: å¯å­¦ä¹ ç¼–ç çš„è¾“å…¥ä¹Ÿåº”è¯¥æ˜¯æ•´ä¸ª NestedTensorï¼Œä»¥ä¾¿æ¨¡å—å†…éƒ¨è·å–Hå’ŒW
    pos_learned = pos_enc_learned(nested_tensor)
    
    # éªŒè¯
    assert pos_learned.shape == expected_shape, f"[Learned] å½¢çŠ¶æ–­è¨€å¤±è´¥! Got {pos_learned.shape}, Expected {expected_shape}"
    assert pos_learned.dtype == torch.float32, f"[Learned] æ•°æ®ç±»å‹åº”ä¸º float32, Got {pos_learned.dtype}"
    
    # éªŒè¯å…¶å‚æ•°æ˜¯å¦â€œå¯å­¦ä¹ â€
    has_learnable_params = any(p.requires_grad for p in pos_enc_learned.parameters())
    assert has_learnable_params, "[Learned] æ¨¡å‹ä¸­æ²¡æœ‰å¯å­¦ä¹ çš„å‚æ•° (requires_grad=False)"

    print(f"âœ… [Learned] å®ä¾‹åˆ›å»ºæˆåŠŸ")
    print(f"âœ… [Learned] è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {pos_learned.shape}")
    print(f"âœ… [Learned] æ•°æ®ç±»å‹æ­£ç¡®: {pos_learned.dtype}")
    print(f"âœ… [Learned] åŒ…å«å¯å­¦ä¹ å‚æ•° (requires_grad=True)")
    print(f"âœ… [Learned] å¯å­¦ä¹ å‚æ•°æ•°é‡: {sum(p.numel() for p in pos_enc_learned.parameters() if p.requires_grad)}")

    print("\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒæµ‹è¯•æ–­è¨€é€šè¿‡ï¼")


if __name__ == "__main__":
    test_position_encoding()
