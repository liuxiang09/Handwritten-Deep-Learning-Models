# CLIP 模型评估结果

## ResNet 架构

| 模型 | 主干网络 | Epoch | 图->文准确率 | 文->图准确率 | 备注 |
|------|--------|---|---------|-------|----|
| CLIP | ResNet | 1 | 73.17% | 64.47% | 无 |
| CLIP | ResNet | 5 | 87.43% | 77.99% | 无 |

## ViT 预训练架构

| 模型 | 主干网络 | Epoch | 图->文准确率 | 文->图准确率 | 备注 |
|------|----------------|---|--------|--------|----|
| CLIP | ViT-pretrained | 1 | 82.62% | 75.42% | 无 |
| CLIP | ViT-pretrained | 5 | **91.04%** | **85.03%** | 无 |

## 观察结果

- ViT预训练架构在所有评估指标上都优于ResNet架构，原因可能是timm中的预训练ViT已在ImageNet数据集上充分训练，达到最优性能。
- ViT架构在仅训练1个epoch时就达到了75.42%的准确率，明显高于ResNet的64.47%
- 目前实验出现的最好结果为ViT架构并在数据集上训练5个epoch的结果，图->文、文->图准确率分别达到了91.04%和84.03%。